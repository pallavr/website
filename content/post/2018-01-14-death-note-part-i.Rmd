---
title: Death Note (Part I)
author: ''
date: '2018-01-14'
slug: death-note-part-i
summary: "Learn how to perform non-parametric and semi-parametric Survival Analysis in R"
categories:
  - predictive analytics
tags:
  - survival analysis
  - ggplot2
  - R
header:
  image: "headers/death.jpg"
---

<style>
body {
text-align: justify}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```


*Death Note* is a Japanese manga series depicting an evil book that would kill people if their names were written on it. Now, there are no such books in the real world, but a field of study called **Survival Analysis** allows statisticians to measure and predict the risk(s) individuals will face. It also allows statisticians to measure the duration of life until an event(s) occurs. The earliest forms of survival analysis originated in the 17th century in the form of **life tables**. It was popularized by the work of the infamous *D.R.Cox* and his **semi-parametric** models.



# The libraries

```{r,message=FALSE,warning=FALSE}
library(invGauss) # has the data
library(dplyr) # data manipulation
library(tidyr) # data manipulation
library(ggplot2) # data viz
library(ggfortify)
library(survival) # survival analysis
```


# The Data

It's very difficult to obtain time-to-event data on the internet. One interesting data set I found is shipped with the `invGauss` package. The data set is about cancer in the oropharynx. This data set was given by  Kalbfleisch and Prentice and has 192 observations or patients with carcinoma of the oropharynx carried out by the Radiation Therapy Oncology Group in the United States.

- **CASE:** Case Number
- **INST:** Participating Institution
- **SEX:** 1=male, 2=female
- **TX:** Treatment: 1=standard, 2=test
- **GRADE:** 1=well differentiated, 2=moderately differentiated,3=poorly differentiated,  9=missing
- **AGE:** In years at time of diagnosis
- **COND:** Condition: 1=no disability, 2=restricted work, 3=requires assistance with self care, 4=bed confined,  9=missing
- **SITE:** 1=facial arch, 2=tonsillar fossa, 3=posterior pillar,4=pharyngeal tongue, 5=posterior wall
- **T_STAGE:** 1=primary tumor measuring 2 cm or less in largest diameter,2=primary tumor measuring 2 cm to 4 cm in largest diameter with minimal infiltration in depth, 3=primary tumor measuring more than 4 cm, 4=massive invasive tumor
- **N_STAGE:** 0=no clinical evidence of node metastases, 1=single positive node 3 cm or less in diameter, not fixed, 2=single positive node more than 3 cm in diameter, not fixed, 3=multiple positive nodes or fixed positive nodes 
- **ENTRY_DT:** Date of study entry: Day of year and year, dddyy
- **STATUS:** 0=censored,  1=dead
- **TIME:** Survival time in days from day of diagnosis

```{r}
data("d.oropha.rec")
data <- d.oropha.rec
```


# Elements of Survival analysis

## Survival Time and Event

The two most important measures in survival studies include: 

- The **time to death** is a number (in days, week or years) that reflects the number of time intervals until which the person experiences the event. Let this be represented by $ t_i $ or *event time*.

- The **status** of the patient is usually a number that identifies whether or not the person has experienced the event. Typically, "0" is used to represent observations that are active (or censored) while "1" is used to represent patients who has experienced the event. Let this be represented by $ \delta_i $


```{r}
survivial_object <- with(data,Surv(time = time, event = status, type = c("right")))

(survivial_object)[1:30]
```

One can create a survival object in R using the `Surv` function. A call to the object shows the observations coded as censored (with the `+`) and non censored. The `time` column in the data represents the time to death or censoring time.

## Censoring

For individuals who have not experienced the event, (called the **censored observations**), we only know the *censoring time* (represented by $ c_i $) or the time for which the particular observation was under study. Therefore, for such observations we do not know the actual event time. Now imagine any individual *i* there is a pair of times 
$ (\tilde{t_i},\tilde{c_i}) $ but depending on the status we choose either one of them. If the individual experiences the event and $\delta_i=1$ we see $t_i$ but if there is no event and the individual is censored, we see $c_i$. This information can be compactly represented by $(min(t_i,c_i),\delta_i)$. The `status` column in the data reflects the status of the individual until event time or censoring time.


# Kaplan Meier Analysis

Kaplan-Meier (KM) estimation is a non parametric method of estimating the survival at time *t*. If you were to order the time in ascending order by the event times $t_i$ and if $\delta_i$ was the number of deaths and let $n_i$ be the number alive just before $t_i$, then the KM or **product limit estimate** of the survivor function is:

$$S(t) = S(t-1)(1 - \frac{d_t}{n_t} )$$

Let's understand where this comes from. Let $t_1,t_2,t_3...$ be the actual times of death of the *n* individuals and let $d_1,d_2,d_3....$ represent the number of deaths during those times and let $n_1,n_2,...$ be the people remaining.
Now, $n_2 = n_1 - d_1$ and so on. So, intuitively the proportion surviving at time $t=2$ depends on the proportion surviving at $t=1$. Now for any time interval say $ t \in [t_1,t_2) $ the survival is:

$$  S(t) = P(T \geq t) = P(\text{survive in}[0,t_1))* P(\text{survive in}[t_1,t]|\text{survive in}[0,t_1))            $$

$$  S(t) = 1 * \frac{n_1-d_1}{n_1}  $$. This bring us to:

$$ S(t) = \prod_{i=1}^{n}(1-\frac{d_i}{n_i}) $$

The Kaplan-Meier estimate is a step function which **discontinuities or jumps** at the observed death times. If there is no censoring, the K-M estimate coincides with the empirical survival function. The KM estimator can also be nicely interpreted as a NPML estimator. The `survfit` function in the `survival` package is used to find out the KM estimates of survival. We can use the `summary` call to the `km` object to get the following:

- **n:** the total number of observations.
- **time:** the time points at which the $S(t)$ is calculated.
- **n.risk:** the number of observations at risk at time t
- **n.event:** the number of events that occurred at time t.
- **n.censor:** the number of censored observations, without an event, at time t.
- **lower,upper:** lower and upper confidence limits for $S(t)$, respectively.
- **strata:** indicates stratification of survival curves. If strata is specified, there are multiple curves in the result. There's a demonstration later on.

```{r}
km.fit <- survfit(survivial_object ~ 1, # for a single survival curve
                  data = data)

time <- km.fit$time
summary(km.fit, times = time[1:20])
```

Here's a neat plot of risk and survival estimated by the `survfit` function.

```{r}
my3cols <- c("#E7B800", "#2E9FDF", "#FC4E07")
my2cols <- c("#2E9FDF", "#FC4E07")

km.df <- data.frame(
  time = time,
  survival = km.fit$surv,
  dead = km.fit$n.event
)

km.df %>%
  mutate(deaths = cumsum(dead)) %>%
  select(time,survival,deaths) %>%
  gather(key, value, -time) %>%
  ggplot(aes(x = time, y = value))+
  geom_point(col = my2cols[2])+
  geom_line(col = my2cols[2])+
  facet_wrap(~key, scales = "free")+
  labs(title = "Survival and Event vs Time")+
  theme_minimal()
```


## KM by groups

As I mentioned before, we can also create these KM estimates by groups. In R the best way to summarise all the information is to use the `ggsurvplot` function from the `survminer` package.

```{r}
km.sex.fit <- survfit(survivial_object ~ sex,
                      data = data)

# Using ggsurv package

survminer::ggsurvplot(
   km.sex.fit,               # survfit object with calculated statistics.
   data = data,
   pval = TRUE,              # show p-value of log-rank test.
   conf.int = TRUE,          # show confidence intervals for 
                             # point estimaes of survival curves.
   conf.int.style = "step",  # customize style of confidence intervals
   xlab = "Time in years",    # customize X axis label.
   ggtheme = theme_light(),  # customize plot and risk table with a theme.
   risk.table = "abs_pct",   # absolute number and percentage at risk.
   risk.table.y.text.col = T,# colour risk table text annotations.
   risk.table.y.text = FALSE,# show bars instead of names in text annotations
   ncensor.plot = TRUE,      # plot the number of censored subjects at time t
   surv.median.line = "hv",  # add the median survival pointer.
   legend.labs = c("Male", "Female"),     # change legend labels.
   palette = my2cols         # custom color palettes.
)

```

The Kaplan-Meier plot can be interpreted as follow:

The x axis represents time in years, and the vertical axis (y-axis) shows the proportion of people surviving. The lines represent survival curves of the two groups. **A vertical drop in the curves indicates an event.** The vertical tick mark on the last plot means that a observation was censored at this time and the group it belongs to.

- At time zero, the survival probability is 1.0 (or 100% of the participants are alive).
- At time 1.5 years, the probability of survival is approximately 0.50 (or 55%) for males. It is slightly higher for females.


## Interpret the output

```{r}
summary(km.sex.fit)$table
```

The median survival time for female is indeed higher. The `rmean` stands for restricted mean survival time. The restricted mean is a measure of average survival from time 0 to a specified time point, and may be estimated as the area under the survival curve up to that point.


**Complicated Groups**

One can also use facet grids to compare survival curves across complex groups.

```{r}
km.sex.treat.fit <- survfit(survivial_object ~ sex + treatm,
                      data = data)

ggsurv <- survminer::ggsurvplot(km.sex.treat.fit, data = data,fun = "cumhaz", conf.int = TRUE)
   
ggsurv$plot +
  theme_minimal() + 
  theme (legend.position = "right")+
  facet_grid(sex ~ treatm)
```

## Hazard

In survival literature, the opposite of survival is hazard. Hazard refers to the instantaneous rate of death of the subject at time $t$ conditional on survival to that time. Mathematically, 

$$  \lambda(t) = \lim_{\Delta t \to 0} \frac{ \text{Pr}\{(t \leq T \leq t+\Delta t)|T \geq t\}   }{\Delta t} = \frac{f(t)}{S(t)}         $$

The numerator in the equation represents the conditional probability that an event will occur within the time interval of $[t,t+\Delta t)$ given that it has not occurred before (that is $ T \geq t $). This conditional probability may be represented by a joint probability (Using the axioms of probability: P(AB) = P(A)P(B|A)). The former is represented by $ f(t) $ in the above equation while the latter is $ S(t) $ by definition. Dividing this by the width of the interval gives us a rate (of death) per unit time.  Therefore, Hazard and survival have a one to one relationship (and it's definitely not **1-Survival**).

One can calculate hazard non parametrically using the **Nelson Aalen Estimator**. Mathematically the NE estimator is:

$$  \hat{H(t)} = \sum_{t_i \leq T}\frac{d_i}{n_i}      $$

with $ d_{i} $ the number of events at $ t_{i} $ and $ n_{i} $ the total individuals at risk at $ t_{i} $. You can also visualize the hazard using the `ggsurvplot` function by specifying the value of `fun` as `cumhaz`.

```{r}
survminer::ggsurvplot(
   km.sex.fit,               # survfit object with calculated statistics.
   data = data,
   fun = "cumhaz",
   pval = TRUE,              # show p-value of log-rank test.
   conf.int = TRUE,          # show confidence intervals for 
                             # point estimaes of survival curves.
   conf.int.style = "step",  # customize style of confidence intervals
   xlab = "Time in years",    # customize X axis label.
   ggtheme = theme_light(),  # customize plot and risk table with a theme.
   risk.table = "abs_pct",   # absolute number and percentage at risk.
   risk.table.y.text.col = T,# colour risk table text annotations.
   risk.table.y.text = FALSE,# show bars instead of names in text annotations
   ncensor.plot = TRUE,      # plot the number of censored subjects at time t
   legend.labs = c("Male", "Female"),     # change legend labels.
   palette = my2cols         # custom color palettes.
)

```



## Comparing Survival Curves

The **Log Rank Test** is the most popular hypothesis test to distinguish two or more survival curves. Basically the LR test compares the Hazard of the two survival curves at every point in time. If you're interested in the formulation and the derivation of the test statistic, the [wikipedia](https://en.wikipedia.org/wiki/Log-rank_test) page has a nice explanation.

The function `survdiff()` [in survival package] can be used to compute log-rank test comparing two or more survival curves.

```{r}
survdiff(survivial_object ~ sex,data = data)
```

The function returns a list of components, including:

- **n:** the number of subjects in each group.
- **obs:** the weighted observed number of events in each group.
- **exp:** the weighted expected number of events in each group.
- **chisq:** the chi square statistic for a test of equality.
- **strata:** optionally, the number of subjects contained in each stratum.

The log rank test for difference in survival gives a p-value of p = 0.4, indicating that the sex groups do not differ significantly in survival.


# Cox Proportional Survival Analysis


The proportional hazards model (introduced by Cox, 1972) is a family of survival models that allow for covariates to be linked to the hazard directly. The first key to this relationship is that its **multiplicative**. This means that we can only allow the logarithm of the hazard to be linked to the covariates by:

$$  \text{log} \lambda_i(t) = \alpha + \beta_1x_{i1} + ...                   $$

or equivalently, 

$$ \lambda_i(t) = \text{exp}(\alpha + \beta_1x_{i1} + ...)   $$. 

**Note:** The $\alpha$ in this multiplicative version represents some sort a *baseline*. If all $x_i$'s are zero, then the logarithm of hazard equals $e^\alpha$. The good part of this family of models is it allows for this baseline to remain unspecified (or we don't necessarily need to compute the coefficient for this intercept-like term).This makes the model *semi-parametric*.

The second key aspect of the Cox model is the **proportionality**. This means that *hazard ratios* of say two observations are *independent of time*. The $\beta$s are estimated using proportionalily. This means that the coefficients are interpreted differently (see below). A value $\beta$ greater than zero, or equivalently a hazard ratio greater than one, indicates that as the value of the ith covariate increases, the event hazard increases and thus the length of survival decreases. Put another way, a hazard ratio above 1 indicates a covariate that is positively associated with the event probability, and thus negatively associated with the length of survival.

In summary,

- HR = 1: No effect
- HR < 1: Reduction in the hazard
- HR > 1: Increase in Hazard


## Fitting the model

The `coxph` function is used to estimate the coefficients of the parameters. The `summary` call then shows all the estimates along with the following output:

```{r}

cox.fit <- coxph(formula = Surv(time,status)~.,
                 data = data[,-1],
                 ties = "efron")

summary(cox.fit)
```

The Cox regression results can be interpreted as follow:

- **Statistical significance:** The is the column under "z" and it corresponds to the ratio of each regression coefficient to its standard error (z = coef/se(coef)). This signifies, whether the coefficient of a given variable is statistically significantly different from 0. 

- **The regression coefficients signs:** A positive sign means that the hazard is higher, and this suggests that with the increase of the variable the hazard increases. For categorical variables the Cox model gives the hazard ratio (HR) for the one group relative to the other group. The beta coefficient for sex = -0.3 indicates that females have *lower* risk of death (lower survival rates) than males.

- **Hazard ratios:** The exponentiated coefficients in the second column of the first panel (and in the first column of the second panel) of the output are interpretable as multiplicative effects on the hazard. Thus, for example,
holding the other covariates constant, an additional year of age reduces the yearly hazard of rearrest by 73 percent.

- **Confidence intervals:** of the hazard ratios. The summary output also gives upper and lower 95% confidence intervals for the hazard ratio (exp(coef))

- **Global statistical significance of the model:** The likelihood-ratio, Wald, and score chi-square statistics at the bottom of the output are asymptotically (for large enough N, they will give similar results. For small N, they may differ somewhat) equivalent tests of the omnibus null hypothesis that all of the beta's are zero. In this instance, the test statistics are in close agreement, and the hypothesis is soundly rejected.


## Survival curves

One can extract the survival probabilities from the cox object in R and simultaneously plot it using the `ggsurvplot` function.

```{r,message=FALSE,warning=FALSE}
survminer::ggsurvplot(survfit(cox.fit), color = "#2E9FDF",ggtheme = theme_minimal())
```

## Assumption Checking

In order to check these model assumptions, Residuals method are used. The common residuals for - the Cox model include:

- **Schoenfeld residuals** to check the proportional hazards assumption
- **Martingale residual** to assess nonlinearity
- **Deviance residuals** (symmetric transformation of the Martingale residuals), to examine influential observations

- **Proportionality:** The proportional hazards (PH) assumption can be checked using statistical tests and graphical diagnostics based on the scaled Schoenfeld residuals. In principle, the Schoenfeld residuals are independent of time. A plot that shows a non-random pattern against time is evidence of violation of the PH assumption. The function `cox.zph` provides a convenient solution to test the proportional hazards assumption for each covariate included in a Cox regression model fit. For each covariate, the function `cox.zph` correlates the corresponding set of scaled Schoenfeld residuals with time, to test for independence between residuals and time. Additionally, it performs a global test for the model as a whole. The proportional hazard assumption is supported by a non-significant relationship between residuals and time, and refuted by a significant relationship.

```{r}
cox.fit <- coxph(formula = Surv(time,status)~ sex + treatm,
                 data = data[,-1],
                 ties = "efron")

cox.zph(cox.fit)
```
From the output above, the test is not statistically significant for each of the covariates, and the global test is also not statistically significant. Therefore, we can assume the proportional hazards. It's possible to do a graphical diagnostic using the function `ggcoxzph`, which produces, for each covariate, graphs of the scaled Schoenfeld residuals against the transformed time.

```{r}
survminer::ggcoxzph(cox.zph(cox.fit))
```

In the figure above, the solid line is a smoothing spline fit to the plot, with the dashed lines representing a +/- 2-standard-error band around the fit. Note that, systematic departures from a horizontal line are indicative of non-proportional hazards, since proportional hazards assumes that estimates do not vary much over time. From the graphical inspection, there is no pattern with time. The assumption of proportional hazards appears to be supported for the covariates sex (which is, recall, a two-level factor, accounting for the two bands in the graph), wt.loss and age.

A violations of proportional hazards assumption can be resolved by:

- Adding covariate*time interaction  
- Stratification  
- Stratification is useful for "nuisance" con founders, where you do not care to estimate the effect. You cannot examine the effects of the stratification variable (John Fox & Sanford Weisberg).

**Influential Observations:** To test influential observations or outliers, we can visualize either the deviance residuals or the dfbeta values. The function `ggcoxdiagnostics` provides a convenient solution for checking influential observations. The simplified format is as follows:

```{r,message=FALSE,message=FALSE}
survminer::ggcoxdiagnostics(cox.fit, type = "martingale" ,linear.predictions = F, ggtheme = ggplot2::theme_minimal())
```

Specifying the argument type = "dfbeta", plots the estimated changes in the regression coefficients upon deleting each observation in turn; likewise, type="dfbetas" produces the estimated changes in the coefficients divided by their standard errors.

For example:

```{r}
survminer::ggcoxdiagnostics(cox.fit, type = "dfbeta" ,linear.predictions = F, ggtheme = ggplot2::theme_minimal())
```

The above index plots show that comparing the magnitudes of the largest dfbeta values to the regression coefficients suggests that none of the observations is terribly influential individually

It's also possible to check outliers by visualizing the deviance residuals. The deviance residual is a normalized transform of the martingale residual. These residuals should be roughly symmetrically distributed about zero with a standard deviation of 1. Positive values correspond to individuals that "died too soon" compared to expected survival times. Negative values correspond to individual that "lived too long". Very large or small values are outliers, which are poorly predicted by the model. Example of deviance residuals:

```{r}
survminer::ggcoxdiagnostics(cox.fit, type = "deviance" ,linear.predictions = F, ggtheme = ggplot2::theme_minimal())
```


- **Non-linearity:**Often, we assume that continuous covariates have a linear form. However, this assumption should be checked. Plotting the Martingale residuals against continuous covariates is a common approach used to detect nonlinearity or, in other words, to assess the functional form of a covariate. For a given continuous covariate, patterns in the plot may suggest that the variable is not properly fit. Nonlinearity is not an issue for categorical variables, so we only examine plots of martingale residuals and partial residuals against a continuous variable.

Martingale residuals may present any value in the range (-INF, +1) and a value of martingale residuals near 1 represents individuals that "died too soon", and large negative values correspond to individuals that "lived too long". To assess the functional form of a continuous variable in a Cox proportional hazards model, we'll use the function `ggcoxfunctional`.

The function displays graphs of continuous covariates against martingale residuals of null cox proportional hazards model. This might help to properly choose the functional form of continuous variable in the Cox model. Fitted lines with lowess function should be linear to satisfy the Cox proportional hazards model assumptions.

```{r,message=FALSE,warning=FALSE}
survminer::ggcoxfunctional(formula = Surv(time,status)~ age + log(age) + sqrt(age), data = data)
```


## Prediction

```{r}
train_test_split <- function(data,percent,seed){
  set.seed(seed)
  rows = sample(nrow(data))
  data <- data[rows,]
  split = round(nrow(data)*percent)
  list(train = data[1:split,], test =  data[(split+1):nrow(data),])
}

list <- train_test_split(data,0.6,66)
train <- list$train; test <- list$test

cox.fit2 <- coxph(formula = Surv(time,status)~.,data = train)

# predict the survival
predictions <- survfit(cox.fit2, newdata = test)

```


## Visualize the predictions

```{r}

# transponse the frame
survival.prediction <- data.frame(t(predictions$surv))
# add IDs
survival.prediction <- cbind(id = test$case,survival.prediction)
# rename column
colnames(survival.prediction) <- c("id",round(predictions$time,3))

survival.prediction %>%
        gather(key,value,-id) %>%
        mutate(key = as.numeric(key)) %>%
        ggplot(aes(x = key, y = value, group = id))+
        geom_line(alpha = 0.25)+
        theme_minimal()+
        labs(y = "Probability",x = "Time", title = "Survival vs Time")+
        theme(axis.text.x = element_blank())+
        scale_x_continuous(breaks = c(0.203,3.608,0.5))


# using pec

predictions.pec <- pec::predictSurvProb(cox.fit2, newdata = test, times = km.fit$time)
       
```

**Cumulative Hazard** at time *t* can also be extracted using the `cumhaz` component.

```{r}
hazard.prediction <- predictions$cumhaz # hazard
```


## Validating the predicton

A measure used to assess the strength of a risk classification system is discrimination, and when the outcome is survival time, the most commonly applied global measure of discrimination is the concordance probability. The concordance probability represents the pairwise probability of lower patient risk given longer survival time. It is the fraction of pairs in your data, where the observation with the higher survival time has the higher probability of survival predicted by your model.

The **Brier score** is a proper score function that measures the accuracy of probabilistic predictions ([wikipedia](https://en.wikipedia.org/wiki/Brier_score)). Evaluating the performance of risk prediction models in survival analysis. The Brier score is a weighted average of the squared distances between the observed survival status and the predicted survival probability of a model. Roughly the weights correspond to the probabilities of not being censored. The weights can be estimated depend on covariates. Prediction error curves are obtained when the Brier score is followed over time. Cross-validation based on bootstrap resampling or bootstrap subsampling can be applied to assess and compare the predictive power of various regression modelling strategies on the same set of data.. We can calculate the Brier Scores for our model and compare it against a reference model (without covariates) and compare the performance.

```{r,message=FALSE,warning=FALSE}
library(pec)
library(prodlim)
library(riskRegression)
set.seed(17)

cindex <- cindex(list(cox.fit2),
                   formula = Hist(time,status) ~ 1,
                   data = data,
                   splitMethod="bootcv",
                   M=round(NROW(data)*.6),
                   B=100,
                   cens.model="marginal")

(cindex$BootCvCindex$coxph)

Brier  <- pec(list(cox.fit2),
                   formula = Hist(time,status) ~ 1,
                   data = data,
                   splitMethod="bootcv",
                   M=round(NROW(data)*.6),
                   B=100,
                   cens.model="marginal")


reference <- Brier$BootCvErr$Reference
cox <- Brier$BootCvErr$coxph
err.frame <- data.frame(reference,cox,time=Brier$time)
err.frame <- err.frame[1:171,]
err.frame.long <- gather(err.frame,key,value,-time)
ggplot(err.frame.long, aes(x = time, y = value, col = key))+
  geom_line()+
  scale_color_manual("Metric",values =c("cox"="red2","reference"="navyblue"))+
  theme_minimal()

```

Clearly the model with all covariates have lower error rates than our reference model with no covariates. One can also check the accuracy of such models by examining the area under the curve by using ROC style analysis.

# Additive models

Additive hazard or Aalen's models are an alternative to proportional hazard models. Here the hazard model is more directly similar to a linear model. Here the covariates are allowed to vary over time. We can also allow the
covariates to vary over time.

$$  \lambda(t|x(t)) = \beta_0(t) + \sum \beta_k(t)x_k(t)             $$

We can fit the additive model in R using the `aareg` function. Then we can use `autoplot` from ggfortify to investigate which coefficients may vary over time.

```{r, message=FALSE, warning=FALSE}

additive <- aareg(Surv(time,status)~., data = data)

additive

autoplot(additive)+
  theme_minimal()+
  theme(legend.position = "top")

```

Sex might vary over time. This is evident from the steep slope in comparison with the rest.

There are several other survival models for instance, accelerated failure time (AFT) model that model survival information using distributions. Part 2 of this tutorial is coming up next where I will demonstrate how to construct survival trees and forests.


